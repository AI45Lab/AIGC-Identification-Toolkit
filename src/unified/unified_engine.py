"""
å¤šæ¨¡æ€æ°´å°å·¥å…·ç»Ÿä¸€å¼•æ“
"""

import torch
import logging
from typing import Dict, Any, Optional, Union
from PIL import Image

try:
    # ç›¸å¯¹å¯¼å…¥ï¼ˆå½“ä½œä¸ºåŒ…è¿è¡Œæ—¶ï¼‰
    from ..text_watermark.text_watermark import TextWatermark
    from ..image_watermark.image_watermark import ImageWatermark
    from ..audio_watermark.audio_watermark import AudioWatermark
    from ..video_watermark.video_watermark import VideoWatermark
except ImportError:
    try:
        # ç»å¯¹å¯¼å…¥ï¼ˆå½“ src åœ¨è·¯å¾„ä¸­æ—¶ï¼‰
        from text_watermark.text_watermark import TextWatermark
        from image_watermark.image_watermark import ImageWatermark
        from audio_watermark.audio_watermark import AudioWatermark
        from video_watermark.video_watermark import VideoWatermark
    except ImportError as e:
        raise ImportError(f"æ— æ³•å¯¼å…¥æ°´å°æ¨¡å—: {e}. è¯·ç¡®ä¿ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œå¹¶ä¸” src ç›®å½•åœ¨ Python è·¯å¾„ä¸­ã€‚")


class UnifiedWatermarkEngine:
    """
    å¤šæ¨¡æ€æ°´å°ç»Ÿä¸€å¼•æ“
    
    éµå¾ªKISSåŸåˆ™çš„ç®€æ´è®¾è®¡ï¼š
    - ç»Ÿä¸€çš„embed/extractæ¥å£
    - ä½¿ç”¨æµ‹è¯•éªŒè¯çš„æœ€ä¼˜é»˜è®¤å‚æ•°
    - å›¾åƒé»˜è®¤ä½¿ç”¨videosealç®—æ³•
    - æ”¯æŒtext/image/audio/videoå››ç§æ¨¡æ€
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–ç»Ÿä¸€æ°´å°å¼•æ“
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.logger = logging.getLogger(__name__)
        
        # å»¶è¿Ÿåˆå§‹åŒ–å„æ¨¡æ€å¤„ç†å™¨ï¼ŒèŠ‚çœå†…å­˜
        self._text_watermark = None
        self._image_watermark = None  
        self._audio_watermark = None
        self._video_watermark = None
        # æ–‡æœ¬æ¨¡å‹ä¸åˆ†è¯å™¨ï¼ˆæ‡’åŠ è½½åç¼“å­˜ï¼‰
        self._text_model = None
        self._text_tokenizer = None
        
        self.config_path = config_path
        
        self.logger.info("UnifiedWatermarkEngineåˆå§‹åŒ–å®Œæˆ")
    
    def _project_root(self) -> str:
        """è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŸºäºå½“å‰æ–‡ä»¶ä½ç½®æ¨æ–­ï¼‰ã€‚"""
        import os
        return os.path.dirname(os.path.dirname(os.path.dirname(__file__)))

    def _candidate_cache_dirs(self) -> list:
        """è¿”å›å¯èƒ½çš„æœ¬åœ°ç¼“å­˜ç›®å½•åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ã€‚"""
        import os
        candidates = []
        if os.getenv('HF_HOME'):
            candidates.append(os.path.join(os.getenv('HF_HOME'), 'hub'))
        if os.getenv('HF_HUB_CACHE'):
            candidates.append(os.getenv('HF_HUB_CACHE'))
        # é¡¹ç›®å†… models ç›®å½•
        candidates.append(os.path.join(self._project_root(), 'models'))
        # ç”¨æˆ·çº§é»˜è®¤ç¼“å­˜
        candidates.append(os.path.expanduser('~/.cache/huggingface/hub'))
        # å»é‡å¹¶ä¿ç•™é¡ºåº
        seen = set()
        ordered = []
        for p in candidates:
            if p and p not in seen:
                seen.add(p)
                ordered.append(p)
        return ordered

    def _load_text_config(self) -> Dict[str, Any]:
        """åŠ è½½æ–‡æœ¬æ°´å°é…ç½®ã€‚ä» config/default_config.yaml çš„ text_watermark èŠ‚è¯»å–ã€‚"""
        import os
        import yaml
        # ä¼˜å…ˆä½¿ç”¨ self.config_path
        cfg_path = None
        if self.config_path and os.path.isfile(self.config_path):
            cfg_path = self.config_path
        else:
            # é»˜è®¤æŒ‡å‘é¡¹ç›®å†… config/default_config.yaml
            default_path = os.path.join(self._project_root(), 'config', 'default_config.yaml')
            if os.path.isfile(default_path):
                cfg_path = default_path
        if cfg_path is None:
            # é€€å›åˆ°å†…ç½®é»˜è®¤ï¼ˆPostMarkåŸºç¡€é…ç½®ï¼‰
            return {
                'algorithm': 'postmark',
                'postmark': {
                    'embedder': 'nomic',
                    'inserter': 'mistral-7b-inst',
                    'ratio': 0.12,
                    'iterate': 'v2',
                    'threshold': 0.7
                }
            }
        with open(cfg_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f) or {}
        # æå– text_watermark èŠ‚ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤é…ç½®
        return data.get('text_watermark', {
            'algorithm': 'postmark',
            'postmark': {
                'embedder': 'nomic',
                'inserter': 'mistral-7b-inst',
                'ratio': 0.12
            }
        })

    def _init_text_model_tokenizer(self):
        """ä½¿ç”¨ä¸ test_complex_messages_real.py ä¸€è‡´çš„ç­–ç•¥åˆå§‹åŒ–æ–‡æœ¬æ¨¡å‹ä¸åˆ†è¯å™¨ï¼ˆç¦»çº¿ä¼˜å…ˆï¼‰ã€‚"""
        if self._text_model is not None and self._text_tokenizer is not None:
            return
        import os
        import torch
        from transformers import AutoModelForCausalLM, AutoTokenizer

        # å¼ºåˆ¶ç¦»çº¿é¦–é€‰ï¼Œé¿å…è”ç½‘ä¾èµ–
        os.environ.setdefault('TRANSFORMERS_OFFLINE', '1')
        os.environ.setdefault('HF_HUB_OFFLINE', '1')

        cfg = self._load_text_config()
        primary_model = cfg.get('model_name', 'sshleifer/tiny-gpt2')
        model_cfg = cfg.get('model_config', {})

        # æ„é€ å€™é€‰æ¨¡å‹åˆ—è¡¨ï¼šä¼˜å…ˆé…ç½®ï¼Œå…¶æ¬¡tinyæ¨¡å‹
        candidate_models = [m for m in [primary_model, 'sshleifer/tiny-gpt2'] if m]

        # éå†å¯èƒ½çš„ç¼“å­˜ç›®å½•å¹¶å°è¯•åŠ è½½
        candidate_cache_dirs = []
        if model_cfg.get('cache_dir'):
            candidate_cache_dirs.append(model_cfg.get('cache_dir'))
        candidate_cache_dirs.extend(self._candidate_cache_dirs())

        trust_remote_code = bool(model_cfg.get('trust_remote_code', True))
        last_error = None

        for model_name in candidate_models:
            for cache_dir in candidate_cache_dirs:
                try:
                    if cache_dir and not os.path.isdir(cache_dir):
                        continue
                    tokenizer = AutoTokenizer.from_pretrained(
                        model_name,
                        cache_dir=cache_dir,
                        local_files_only=True,
                        trust_remote_code=trust_remote_code,
                        use_fast=True
                    )
                    model = AutoModelForCausalLM.from_pretrained(
                        model_name,
                        cache_dir=cache_dir,
                        local_files_only=True,
                        trust_remote_code=trust_remote_code,
                        device_map=model_cfg.get('device_map', 'auto'),
                        torch_dtype=(torch.float16 if torch.cuda.is_available() else torch.float32)
                    )
                    if tokenizer.pad_token is None:
                        tokenizer.pad_token = tokenizer.eos_token
                    self._text_model = model
                    self._text_tokenizer = tokenizer
                    self.logger.info(f"æ–‡æœ¬æ¨¡å‹åŠ è½½æˆåŠŸ: {model_name} (cache_dir={cache_dir})")
                    return
                except Exception as e:
                    last_error = e
                    continue

        # è‹¥å…¨éƒ¨å¤±è´¥ï¼Œè®°å½•è­¦å‘Š
        self.logger.warning(f"ç¦»çº¿åŠ è½½æ–‡æœ¬æ¨¡å‹å¤±è´¥ï¼Œç¨ååœ¨è°ƒç”¨æ—¶ä»å°†æŠ¥é”™ã€‚æœ€åé”™è¯¯: {last_error}")

    def _get_text_watermark(self) -> TextWatermark:
        """è·å–æ–‡æœ¬æ°´å°å¤„ç†å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._text_watermark is None:
            # ä½¿ç”¨ç»Ÿä¸€çš„TextWatermarké—¨é¢ï¼Œæ”¯æŒå¤šç®—æ³•
            self._text_watermark = TextWatermark(self.config_path)

            # å¦‚æœä½¿ç”¨CredIDç®—æ³•ï¼Œéœ€è¦åˆå§‹åŒ–æ¨¡å‹ä¸åˆ†è¯å™¨
            if self._text_watermark.algorithm == 'credid':
                self._init_text_model_tokenizer()

            self.logger.info(f"æ–‡æœ¬æ°´å°å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œç®—æ³•: {self._text_watermark.algorithm}")
        return self._text_watermark
    
    def _get_image_watermark(self) -> ImageWatermark:
        """è·å–å›¾åƒæ°´å°å¤„ç†å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._image_watermark is None:
            self._image_watermark = ImageWatermark(self.config_path)
            # è®¾ç½®ä¸ºvideosealç®—æ³•ï¼ˆé»˜è®¤ï¼‰
            self._image_watermark.algorithm = 'videoseal'
        return self._image_watermark
    
    def _get_audio_watermark(self) -> AudioWatermark:
        """è·å–éŸ³é¢‘æ°´å°å¤„ç†å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._audio_watermark is None:
            self._audio_watermark = AudioWatermark(self.config_path)
        return self._audio_watermark
    
    def _get_video_watermark(self) -> VideoWatermark:
        """è·å–è§†é¢‘æ°´å°å¤„ç†å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._video_watermark is None:
            from ..video_watermark.video_watermark import create_video_watermark
            self._video_watermark = create_video_watermark()
        return self._video_watermark
    
    def embed(self, content: str, message: str, modality: str, operation: str = 'watermark', **kwargs) -> Any:
        """
        ç»Ÿä¸€åµŒå…¥æ¥å£

        Args:
            content: è¾“å…¥å†…å®¹
                - watermarkæ¨¡å¼ï¼šæç¤ºè¯(AIç”Ÿæˆ) æˆ– å®é™…å†…å®¹(æ–‡ä»¶ä¸Šä¼ )
                - visible_markæ¨¡å¼ï¼šè¦æ·»åŠ æ ‡è¯†çš„å®é™…å†…å®¹
            message: è¦åµŒå…¥çš„æ°´å°æ¶ˆæ¯æˆ–æ ‡è¯†æ–‡æœ¬
            modality: æ¨¡æ€ç±»å‹ ('text', 'image', 'audio', 'video')
            operation: æ“ä½œç±»å‹ ('watermark', 'visible_mark')ï¼Œé»˜è®¤ä¸º 'watermark'
            **kwargs: é¢å¤–å‚æ•°ï¼ˆå¦‚model, tokenizerç­‰ï¼‰

        Returns:
            å¤„ç†åçš„å†…å®¹ï¼ˆå…·ä½“ç±»å‹å–å†³äºæ¨¡æ€å’Œæ“ä½œï¼‰
            - text: str
            - image: PIL.Image
            - audio: torch.Tensor æˆ– strï¼ˆå¦‚æœæŒ‡å®šoutput_pathï¼‰
            - video: strï¼ˆè§†é¢‘æ–‡ä»¶è·¯å¾„ï¼‰
        """
        self.logger.info(f"å¼€å§‹{operation}æ“ä½œ: modality={modality}, content='{content[:50] if isinstance(content, str) else type(content).__name__}...', message='{message}'")

        try:
            # æ ¹æ®æ“ä½œç±»å‹åˆ†å‘åˆ°ä¸åŒçš„å¤„ç†æ–¹æ³•
            if operation == 'watermark':
                return self._embed_watermark(content, message, modality, **kwargs)
            elif operation == 'visible_mark':
                return self._embed_visible_mark(content, message, modality, **kwargs)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {operation}")

        except Exception as e:
            self.logger.error(f"{operation}æ“ä½œå¤±è´¥: {e}")
            raise

    def _embed_watermark(self, content: str, message: str, modality: str, **kwargs) -> Any:
        """
        åŸæœ‰çš„æ°´å°åµŒå…¥é€»è¾‘

        Args:
            content: è¾“å…¥æç¤ºï¼ˆåŸpromptå‚æ•°ï¼‰
            message: æ°´å°æ¶ˆæ¯
            modality: æ¨¡æ€ç±»å‹
            **kwargs: é¢å¤–å‚æ•°
        """
        try:
            if modality == 'text':
                # æ–‡æœ¬æ°´å°ï¼šæ ¹æ®ç®—æ³•ç±»å‹å†³å®šå¤„ç†æ–¹å¼
                watermark = self._get_text_watermark()

                # æ ¹æ®ç®—æ³•ç±»å‹è°ƒç”¨ä¸åŒçš„æ¥å£
                if watermark.algorithm == 'credid':
                    # CredID: éœ€è¦æ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œcontentæ˜¯prompt
                    model = kwargs.get('model') or self._text_model
                    tokenizer = kwargs.get('tokenizer') or self._text_tokenizer

                    if model is None or tokenizer is None:
                        raise ValueError("CredIDç®—æ³•éœ€è¦æä¾›modelå’Œtokenizerå‚æ•°")

                    result = watermark.embed_watermark(content, message, model=model, tokenizer=tokenizer)

                    if result.get('success'):
                        return result['watermarked_text']
                    else:
                        raise RuntimeError(f"CredIDæ°´å°åµŒå…¥å¤±è´¥: {result.get('error', 'Unknown error')}")

                elif watermark.algorithm == 'postmark':
                    # PostMark: åŒºåˆ†AIç”Ÿæˆæ¨¡å¼å’Œæ–‡ä»¶ä¸Šä¼ æ¨¡å¼
                    if 'text_input' in kwargs:
                        # æ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼šcontentæ˜¯å·²ç”Ÿæˆçš„æ–‡æœ¬ï¼Œåå¤„ç†åµŒå…¥
                        result = watermark.embed_watermark(content, message, **kwargs)
                    else:
                        # AIç”Ÿæˆæ¨¡å¼ï¼šcontentæ˜¯promptï¼Œå…ˆç”Ÿæˆå†åµŒå…¥æ°´å°
                        result = watermark.generate_with_watermark(
                            prompt=content,
                            message=message,
                            **kwargs
                        )
                        # generate_with_watermarkè¿”å›å­—ç¬¦ä¸²ï¼Œéœ€åŒ…è£…ä¸ºæ ‡å‡†æ ¼å¼
                        if isinstance(result, str):
                            return result
                        elif isinstance(result, dict) and result.get('success'):
                            return result['watermarked_text']
                        else:
                            raise RuntimeError(f"PostMarkç”Ÿæˆå¤±è´¥: {result.get('error', 'Unknown error') if isinstance(result, dict) else 'Unknown'}")

                    if result.get('success'):
                        return result['watermarked_text']
                    else:
                        raise RuntimeError(f"PostMarkæ°´å°åµŒå…¥å¤±è´¥: {result.get('error', 'Unknown error')}")

                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æ–‡æœ¬æ°´å°ç®—æ³•: {watermark.algorithm}")


            elif modality == 'image':
                # å›¾åƒæ°´å°ï¼šä½¿ç”¨videosealç®—æ³•
                watermark = self._get_image_watermark()
                if 'image_input' in kwargs:
                    # åœ¨ç°æœ‰å›¾åƒä¸ŠåµŒå…¥æ°´å°
                    image_input = kwargs.pop('image_input')  # ç§»é™¤é¿å…é‡å¤ä¼ é€’
                    return watermark.embed_watermark(
                        image_input,
                        message=message,
                        **kwargs
                    )
                else:
                    # ç”Ÿæˆæ–°å›¾åƒå¹¶åµŒå…¥æ°´å°
                    # ğŸ†• AIç”Ÿæˆæ¨¡å¼ï¼šè¯·æ±‚è¿”å›åŸå§‹å›¾åƒ
                    return watermark.generate_with_watermark(
                        content,
                        message=message,
                        return_original=True,  # è¯·æ±‚åŒæ—¶è¿”å›åŸå§‹å›¾åƒ
                        **kwargs
                    )

            elif modality == 'audio':
                # éŸ³é¢‘æ°´å°ï¼šä½¿ç”¨audiosealç®—æ³•
                watermark = self._get_audio_watermark()
                if 'audio_input' in kwargs:
                    # åœ¨ç°æœ‰éŸ³é¢‘ä¸ŠåµŒå…¥æ°´å°
                    audio_input = kwargs.pop('audio_input')  # ç§»é™¤audio_inputé¿å…é‡å¤
                    return watermark.embed_watermark(
                        audio_input,
                        message,
                        **kwargs
                    )
                else:
                    # æ–‡æœ¬è½¬è¯­éŸ³+æ°´å°
                    # ğŸ†• å¯¹äºAIç”ŸæˆéŸ³é¢‘ï¼Œä¼ é€’ return_original=True ä»¥æ”¯æŒå¯¹æ¯”æ˜¾ç¤º
                    return watermark.generate_audio_with_watermark(
                        content,
                        message,
                        return_original=True,
                        **kwargs
                    )

            elif modality == 'video':
                # è§†é¢‘æ°´å°ï¼šHunyuanVideo + VideoSeal
                watermark = self._get_video_watermark()
                if 'video_input' in kwargs:
                    # åœ¨ç°æœ‰è§†é¢‘ä¸ŠåµŒå…¥æ°´å°
                    video_input = kwargs.pop('video_input')  # ç§»é™¤video_inputé¿å…é‡å¤
                    return watermark.embed_watermark(
                        video_input,
                        message,
                        **kwargs
                    )
                else:
                    # æ–‡ç”Ÿè§†é¢‘+æ°´å°
                    # è‹¥æœªä¼ å…¥åˆ†è¾¨ç‡ï¼Œè®¾ç½®æ›´å®‰å…¨çš„é»˜è®¤åˆ†è¾¨ç‡ï¼ˆ16å€æ•°ï¼‰
                    if 'height' not in kwargs:
                        kwargs['height'] = 320
                    if 'width' not in kwargs:
                        kwargs['width'] = 512
                    # ğŸ†• AIç”Ÿæˆæ¨¡å¼ï¼šè¯·æ±‚è¿”å›åŸå§‹è§†é¢‘
                    return watermark.generate_video_with_watermark(
                        content,
                        message,
                        return_original=True,  # è¯·æ±‚åŒæ—¶è¿”å›åŸå§‹è§†é¢‘
                        **kwargs
                    )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡æ€ç±»å‹: {modality}")

        except Exception as e:
            self.logger.error(f"{modality}æ°´å°åµŒå…¥å¤±è´¥: {e}")
            raise

    def _embed_visible_mark(self, content: Any, message: str, modality: str, **kwargs) -> Any:
        """
        æ˜¾å¼æ ‡è¯†åµŒå…¥é€»è¾‘

        Args:
            content: è¦æ·»åŠ æ ‡è¯†çš„å®é™…å†…å®¹
                - text: æ–‡æœ¬å­—ç¬¦ä¸²
                - image: PIL.Imageå¯¹è±¡æˆ–å›¾åƒæ–‡ä»¶è·¯å¾„
                - audio: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
                - video: è§†é¢‘æ–‡ä»¶è·¯å¾„
            message: æ ‡è¯†æ–‡æœ¬
            modality: æ¨¡æ€ç±»å‹
            **kwargs: é¢å¤–å‚æ•°
        """
        # å¯¼å…¥æ˜¾å¼æ ‡è¯†æ¨¡å—
        try:
            # é¦–å…ˆå°è¯•ç›¸å¯¹å¯¼å…¥
            from ..utils.visible_mark import (
                add_text_mark_to_text,
                add_overlay_to_image,
                add_overlay_to_video_ffmpeg,
                add_voice_mark_to_audio
            )
        except ImportError:
            try:
                # å›é€€åˆ°ç»å¯¹å¯¼å…¥
                from src.utils.visible_mark import (
                    add_text_mark_to_text,
                    add_overlay_to_image,
                    add_overlay_to_video_ffmpeg,
                    add_voice_mark_to_audio
                )
            except ImportError:
                # æœ€åå°è¯•ç›´æ¥å¯¼å…¥
                from utils.visible_mark import (
                    add_text_mark_to_text,
                    add_overlay_to_image,
                    add_overlay_to_video_ffmpeg,
                    add_voice_mark_to_audio
                )

        try:
            if modality == 'text':
                # æ–‡æœ¬æ˜¾å¼æ ‡è¯†
                position = kwargs.get('position', 'start')
                return add_text_mark_to_text(content, message, position)

            elif modality == 'image':
                # å›¾åƒæ˜¾å¼æ ‡è¯†
                if isinstance(content, str):
                    # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„ï¼ŒåŠ è½½å›¾åƒ
                    from PIL import Image
                    image = Image.open(content)
                else:
                    # å¦‚æœæ˜¯PIL.Imageå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
                    image = content

                return add_overlay_to_image(
                    image,
                    message,
                    position=kwargs.get('position', 'bottom_right'),
                    font_percent=kwargs.get('font_percent', 5.0),
                    font_color=kwargs.get('font_color', '#FFFFFF'),
                    bg_rgba=kwargs.get('bg_rgba', None)
                )

            elif modality == 'audio':
                # éŸ³é¢‘æ˜¾å¼æ ‡è¯†
                output_path = kwargs.get('output_path')
                if not output_path:
                    # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºè·¯å¾„
                    output_path = self._generate_output_path(content, 'audio', 'visible_mark')

                return add_voice_mark_to_audio(
                    content,
                    output_path,
                    message,
                    position=kwargs.get('position', 'start'),
                    voice_preset=kwargs.get('voice_preset', 'v2/zh_speaker_6')
                )

            elif modality == 'video':
                # è§†é¢‘æ˜¾å¼æ ‡è¯†
                output_path = kwargs.get('output_path')
                if not output_path:
                    output_path = self._generate_output_path(content, 'video', 'visible_mark')

                return add_overlay_to_video_ffmpeg(
                    content,
                    output_path,
                    message,
                    position=kwargs.get('position', 'bottom_right'),
                    font_percent=kwargs.get('font_percent', 5.0),
                    duration_seconds=kwargs.get('duration_seconds', 2.0),
                    font_color=kwargs.get('font_color', 'white'),
                    box_color=kwargs.get('box_color', 'transparent')
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡æ€ç±»å‹: {modality}")

        except Exception as e:
            self.logger.error(f"{modality}æ˜¾å¼æ ‡è¯†æ·»åŠ å¤±è´¥: {e}")
            raise

    def _generate_output_path(self, input_path: str, modality: str, operation: str) -> str:
        """ç”Ÿæˆç»Ÿä¸€çš„è¾“å‡ºè·¯å¾„"""
        import os
        from pathlib import Path
        from datetime import datetime

        input_path = Path(input_path)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        if operation == 'visible_mark':
            suffix = 'marked'
        else:
            suffix = 'watermarked'

        # ç¡®å®šæ–‡ä»¶æ‰©å±•å
        if modality == 'audio':
            ext = '.wav'
        elif modality == 'video':
            ext = '.mp4'
        else:
            ext = input_path.suffix

        output_name = f"{input_path.stem}_{suffix}_{timestamp}{ext}"
        output_dir = Path("demo_outputs")
        output_dir.mkdir(exist_ok=True)

        return str(output_dir / output_name)
    
    def extract(self, content: Any, modality: str, operation: str = 'watermark', **kwargs) -> Dict[str, Any]:
        """
        ç»Ÿä¸€æå–æ¥å£

        Args:
            content: å¾…æ£€æµ‹å†…å®¹
                - text: str
                - image: PIL.Image æˆ– strï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
                - audio: torch.Tensor æˆ– strï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
                - video: strï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
            modality: æ¨¡æ€ç±»å‹ ('text', 'image', 'audio', 'video')
            operation: æ“ä½œç±»å‹ ('watermark', 'visible_mark')ï¼Œé»˜è®¤ä¸º 'watermark'
            **kwargs: é¢å¤–å‚æ•°

        Returns:
            Dict[str, Any]: ç»Ÿä¸€æ ¼å¼çš„æ£€æµ‹ç»“æœ
                - detected: bool, æ˜¯å¦æ£€æµ‹åˆ°æ°´å°/æ ‡è¯†
                - message: str, æå–çš„æ¶ˆæ¯
                - confidence: float, ç½®ä¿¡åº¦ (0.0-1.0)
                - metadata: dict, é¢å¤–ä¿¡æ¯
        """
        self.logger.info(f"å¼€å§‹{operation}æå–æ“ä½œ: modality={modality}")

        try:
            # æ ¹æ®æ“ä½œç±»å‹åˆ†å‘åˆ°ä¸åŒçš„å¤„ç†æ–¹æ³•
            if operation == 'watermark':
                return self._extract_watermark(content, modality, **kwargs)
            elif operation == 'visible_mark':
                return self._extract_visible_mark(content, modality, **kwargs)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {operation}")

        except Exception as e:
            self.logger.error(f"{operation}æå–å¤±è´¥: {e}")
            return {
                'detected': False,
                'message': '',
                'confidence': 0.0,
                'metadata': {'error': str(e), 'operation': operation}
            }

    def _extract_watermark(self, content: Any, modality: str, **kwargs) -> Dict[str, Any]:
        """
        åŸæœ‰çš„æ°´å°æå–é€»è¾‘

        Args:
            content: å¾…æ£€æµ‹å†…å®¹
            modality: æ¨¡æ€ç±»å‹
            **kwargs: é¢å¤–å‚æ•°
        """
        try:
            if modality == 'text':
                watermark = self._get_text_watermark()

                # æ ¹æ®ç®—æ³•ç±»å‹è°ƒç”¨ä¸åŒçš„æå–æ–¹æ³•
                if watermark.algorithm == 'credid':
                    # CredIDéœ€è¦æ¨¡å‹å’Œåˆ†è¯å™¨å‚æ•°
                    model = kwargs.get('model') or self._text_model
                    tokenizer = kwargs.get('tokenizer') or self._text_tokenizer

                    if model is None or tokenizer is None:
                        raise ValueError("CredIDç®—æ³•éœ€è¦æä¾›modelå’Œtokenizerå‚æ•°")

                    result = watermark.extract_watermark(
                        content,
                        model=model,
                        tokenizer=tokenizer,
                        candidates_messages=kwargs.get('candidates_messages'),
                        **kwargs
                    )

                elif watermark.algorithm == 'postmark':
                    # PostMarkæå–
                    result = watermark.extract_watermark(
                        content,
                        candidates_messages=kwargs.get('candidates_messages'),
                        **kwargs
                    )

                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æ–‡æœ¬æ°´å°ç®—æ³•: {watermark.algorithm}")

                # TextWatermarkå·²è¿”å›ç»Ÿä¸€æ ¼å¼
                return result

            elif modality == 'image':
                watermark = self._get_image_watermark()
                # ä½¿ç”¨ä¼˜åŒ–çš„VideoSealå‚æ•°ï¼šreplicate=32æé«˜å¤šå¸§å¹³å‡ç¨³å®šæ€§ï¼Œchunk_size=16ä¼˜åŒ–åˆ†å—å¤„ç†
                result = watermark.extract_watermark(
                    content,
                    replicate=kwargs.get('replicate', 32),
                    chunk_size=kwargs.get('chunk_size', 16),
                    **kwargs
                )
                return {
                    'detected': result.get('detected', False),
                    'message': result.get('message', ''),
                    'confidence': result.get('confidence', 0.0),
                    'metadata': result.get('metadata', {})
                }

            elif modality == 'audio':
                watermark = self._get_audio_watermark()
                result = watermark.extract_watermark(content, **kwargs)
                return {
                    'detected': result.get('detected', False),
                    'message': result.get('message', ''),
                    'confidence': result.get('confidence', 0.0),
                    'metadata': result.get('metadata', {})
                }

            elif modality == 'video':
                watermark = self._get_video_watermark()
                # ä½¿ç”¨æµ‹è¯•éªŒè¯çš„é»˜è®¤å‚æ•°
                result = watermark.extract_watermark(
                    content,
                    chunk_size=kwargs.get('chunk_size', 16),
                    **kwargs
                )
                return {
                    'detected': result.get('detected', False),
                    'message': result.get('message', ''),
                    'confidence': result.get('confidence', 0.0),
                    'metadata': result.get('metadata', {})
                }
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡æ€ç±»å‹: {modality}")

        except Exception as e:
            self.logger.error(f"{modality}æ°´å°æå–å¤±è´¥: {e}")
            return {
                'detected': False,
                'message': '',
                'confidence': 0.0,
                'metadata': {'error': str(e)}
            }

    def _extract_visible_mark(self, content: Any, modality: str, **kwargs) -> Dict[str, Any]:
        """
        æ˜¾å¼æ ‡è¯†æ£€æµ‹é€»è¾‘ï¼ˆé¢„ç•™æ¥å£ï¼‰

        Args:
            content: å¾…æ£€æµ‹å†…å®¹
            modality: æ¨¡æ€ç±»å‹
            **kwargs: é¢å¤–å‚æ•°

        Returns:
            Dict[str, Any]: ç»Ÿä¸€æ ¼å¼çš„æ£€æµ‹ç»“æœ
        """
        self.logger.info(f"æ˜¾å¼æ ‡è¯†æ£€æµ‹: modality={modality}")

        try:
            if modality == 'text':
                # æ–‡æœ¬æ¨¡æ€ï¼šæ£€æµ‹æ˜¯å¦åŒ…å«åˆè§„æ ‡è¯†æ–‡æœ¬
                lines = content.split('\n')
                for line in lines:
                    if 'äººå·¥æ™ºèƒ½' in line and ('ç”Ÿæˆ' in line or 'åˆæˆ' in line):
                        return {
                            'detected': True,
                            'message': line.strip(),
                            'confidence': 1.0,
                            'metadata': {
                                'operation': 'visible_mark',
                                'modality': modality,
                                'detection_method': 'text_pattern_match'
                            }
                        }
                return {
                    'detected': False,
                    'message': '',
                    'confidence': 0.0,
                    'metadata': {'operation': 'visible_mark', 'modality': modality}
                }
            else:
                # å…¶ä»–æ¨¡æ€ï¼šæ˜¾å¼æ ‡è¯†é€šå¸¸æ˜¯å¯è§çš„ï¼Œæå–æ„ä¹‰æœ‰é™
                return {
                    'detected': None,  # æ— æ³•è‡ªåŠ¨æ£€æµ‹
                    'message': 'æ˜¾å¼æ ‡è¯†æ£€æµ‹æš‚ä¸æ”¯æŒæ­¤æ¨¡æ€',
                    'confidence': 0.0,
                    'metadata': {
                        'operation': 'visible_mark',
                        'modality': modality,
                        'note': 'æ˜¾å¼æ ‡è¯†é€šå¸¸æ˜¯å¯è§çš„ï¼Œæ— éœ€æå–'
                    }
                }

        except Exception as e:
            self.logger.error(f"æ˜¾å¼æ ‡è¯†æ£€æµ‹å¤±è´¥: {e}")
            return {
                'detected': False,
                'message': '',
                'confidence': 0.0,
                'metadata': {'error': str(e), 'operation': 'visible_mark'}
            }
    
    def get_supported_modalities(self) -> list:
        """è·å–æ”¯æŒçš„æ¨¡æ€åˆ—è¡¨"""
        return ['text', 'image', 'audio', 'video']
    
    def get_default_algorithms(self) -> Dict[str, str]:
        """è·å–å„æ¨¡æ€çš„é»˜è®¤ç®—æ³•"""
        return {
            'text': 'postmark',  # é»˜è®¤ä½¿ç”¨PostMarkï¼ˆåå¤„ç†æ°´å°ï¼Œæ”¯æŒé»‘ç›’LLMï¼‰
            'image': 'videoseal',  # é»˜è®¤ä½¿ç”¨videoseal
            'audio': 'audioseal',
            'video': 'hunyuan+videoseal'
        }

    def get_supported_operations(self) -> list:
        """è·å–æ”¯æŒçš„æ“ä½œåˆ—è¡¨"""
        return ['watermark', 'visible_mark']

    def get_operation_info(self) -> Dict[str, Dict]:
        """è·å–æ“ä½œä¿¡æ¯"""
        return {
            'watermark': {
                'description': 'éšå¼æ°´å°ï¼Œç”¨äºç‰ˆæƒä¿æŠ¤å’Œå†…å®¹æº¯æº',
                'modalities': ['text', 'image', 'audio', 'video'],
                'supports_extract': True
            },
            'visible_mark': {
                'description': 'æ˜¾å¼æ ‡è¯†ï¼Œç”¨äºAIç”Ÿæˆå†…å®¹åˆè§„æ ‡æ³¨',
                'modalities': ['text', 'image', 'audio', 'video'],
                'supports_extract': True  # æ–‡æœ¬æ¨¡æ€æ”¯æŒç®€å•æ£€æµ‹ï¼Œå…¶ä»–æ¨¡æ€è¿”å›è¯´æ˜ä¿¡æ¯
            }
        }


# ä¾¿æ·å·¥å‚å‡½æ•°
def create_unified_engine(config_path: Optional[str] = None) -> UnifiedWatermarkEngine:
    """
    åˆ›å»ºç»Ÿä¸€æ°´å°å¼•æ“çš„ä¾¿æ·å‡½æ•°
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        UnifiedWatermarkEngine: ç»Ÿä¸€æ°´å°å¼•æ“å®ä¾‹
    """
    return UnifiedWatermarkEngine(config_path)


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    logging.basicConfig(level=logging.INFO)
    
    engine = create_unified_engine()
    
    print("æ”¯æŒçš„æ¨¡æ€:", engine.get_supported_modalities())
    print("é»˜è®¤ç®—æ³•:", engine.get_default_algorithms())
    
    print("UnifiedWatermarkEngineæµ‹è¯•å®Œæˆ")